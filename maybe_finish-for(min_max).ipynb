{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 받아오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"Books_5.json\",\"r\") as data_file:\n",
    "    raw_data=data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_list = []\n",
    "for i in range(len(raw_data)):\n",
    "    try:\n",
    "        json_data = json.loads(raw_data[i])\n",
    "        json_list.append(json_data)\n",
    "    except:\n",
    "        print(raw_data[i],i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review_data = []\n",
    "\n",
    "for i in range(len(json_list)):\n",
    "    review_dict={}\n",
    "    review_dict[\"reviewText\"] = json_list[i][\"reviewText\"]\n",
    "    review_dict[\"overall\"] = json_list[i][\"overall\"]\n",
    "    review_data.append(review_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewText = []\n",
    "for i in range(len(review_data)):\n",
    "    reviewText.append(review_data[i][\"reviewText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"An amazing work. Realizing extensive use of Biblical imagery and sentence structure, &#34;The Prophet&#34; by Khalil Gibran is a literary classic. Influencing the Free Love movement of the 1960's, Gibran's master work explores themes of love, longing and loss.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewText[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_data = []\n",
    "for i in range(len(review_data)):\n",
    "    y_data.append(review_data[i][\"overall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 323833, 2.0: 415110, 3.0: 955189, 4.0: 2223094, 5.0: 4980815})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>데이터 전처리</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "   \n",
    "    cleaned_text_list=[]\n",
    "    for i in range(len(raw_review)):\n",
    "        \n",
    "        review_text = BeautifulSoup(raw_review[i]).get_text()\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "        words = letters_only.lower().split()\n",
    "        cleaned_text = \" \".join(words)\n",
    "        cleaned_text_list.append(cleaned_text)\n",
    "\n",
    "    return cleaned_text_list\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 170 of the file c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n",
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://www.examiner.com/review/maelstroms-the-bangkok-of-timothy-halliman?cid=db_articles\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'.'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n",
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bookjunkiemom.blogspot.com/2014/07/the-respect-dare-40-days-to-deeper.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://bookjunkiemom.blogspot.com/2014/07/dandelions-on-wind-by-mona-hodgson.html\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"http://youtu.be/8Gv0H-vPoDc\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n",
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:282: UserWarning: \"https://www.goodreads.com/review/show/842746405?book_show_action=false\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  ' that document to Beautiful Soup.' % decoded_markup\n"
     ]
    }
   ],
   "source": [
    "pre_data=review_to_words(reviewText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8898041"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pre_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셔플"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = list(zip(pre_data, y_data))\n",
    "random.shuffle(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_text=list(a)\n",
    "overall=np.array(list(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', sublinear_tf=True,lowercase=True)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "tfidf = vectorizer.fit_transform(pre_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가장 작은 평점으로 갯수 맞추기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "length=sorted(Counter(overall).most_common())[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search=[1.0,2.0,3.0,4.0,5.0]\n",
    "count=0\n",
    "text=[]\n",
    "y=[]\n",
    "\n",
    "for i in search:\n",
    "    count=0\n",
    "    for index,value in enumerate(overall):\n",
    "        if (count==length): break\n",
    "        elif (i==value):\n",
    "            text.append(pre_text[index])\n",
    "            y.append(value)\n",
    "            count=count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 323833, 2.0: 323833, 3.0: 323833, 4.0: 323833, 5.0: 323833})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1619165 1619165\n"
     ]
    }
   ],
   "source": [
    "print(len(text), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>데이터 셔플 다시</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = list(zip(text, y))\n",
    "random.shuffle(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a, b = zip(*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data=list(a)\n",
    "overall_data=np.array(list(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', sublinear_tf=True,lowercase=True)\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "tfidf = vectorizer.fit_transform(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(tfidf , overall_data , test_size=0.33, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1084840, 20596668), (1084840,), (534325, 20596668), (534325,))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiclass SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import datasets\n",
    "# from sklearn.multiclass import OneVsRestClassifier\n",
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "# result = OneVsRestClassifier(LinearSVC(random_state=100)).fit(x_train, y_train)\n",
    "# result = result.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55077153417863656"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# accuracy_score(result ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.63      0.69      0.66    106659\n",
      "        2.0       0.48      0.44      0.46    107247\n",
      "        3.0       0.50      0.46      0.48    106991\n",
      "        4.0       0.49      0.47      0.48    106970\n",
      "        5.0       0.63      0.70      0.66    106458\n",
      "\n",
      "avg / total       0.54      0.55      0.55    534325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ...,  True, False, False], dtype=bool)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "logreg.predict(x_test)==y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58050250315819019"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(logreg.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71789535,  0.46698742,  0.49167687,  0.49688698,  0.73049466])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(logreg.predict(x_test), y_test,average=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11702783317605014"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr_1, tpr_1, thresholds = metrics.roc_curve(y_test, logreg.predict(x_test), pos_label=1)\n",
    "metrics.auc(fpr_1, tpr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2684977087352195"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_2, tpr_2, thresholds = metrics.roc_curve(y_test, logreg.predict(x_test), pos_label=2)\n",
    "metrics.auc(fpr_2, tpr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49178580122519733"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_3, tpr_3, thresholds = metrics.roc_curve(y_test, logreg.predict(x_test), pos_label=3) ######여기다시\n",
    "metrics.auc(fpr_3, tpr_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73553431905837741"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_4, tpr_4, thresholds = metrics.roc_curve(y_test, logreg.predict(x_test), pos_label=4)\n",
    "metrics.auc(fpr_4, tpr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88816411987429345"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr_5, tpr_5, thresholds = metrics.roc_curve(y_test, logreg.predict(x_test), pos_label=5)\n",
    "metrics.auc(fpr_5, tpr_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  4.  1.  1.  2.  4.  3.  1.  2.  3.  5.  1.  2.  4.  2.  4.  1.\n",
      "  1.  4.] [ 1.  1.  5.  1.  1.  2.  4.  3.  1.  2.  3.  5.  2.  2.  5.  1.  5.  1.\n",
      "  2.  4.]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:20], logreg.predict(x_test)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  5.,  1.,  1.,  2.,  4.,  3.,  1.,  2.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict(x_test)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        1.0       0.64      0.72      0.68    106659\n",
      "        2.0       0.52      0.47      0.49    107247\n",
      "        3.0       0.54      0.49      0.51    106991\n",
      "        4.0       0.53      0.50      0.51    106970\n",
      "        5.0       0.65      0.73      0.69    106458\n",
      "\n",
      "avg / total       0.57      0.58      0.58    534325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INPUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [\"\"\"I enjoyed this book, as long as I kept in mind that the book was written for young adults.  \n",
    "         The characters were believable and it was easy to identify with their pain.\"\"\",\n",
    "        \"I think the author gets lost in his own thoughts and trys to make storys of something that's not there.\",\n",
    "        \"\"\"I was very excited to start reading this book and although I did like it, \n",
    "        I thought that a lot of the words to describe body parts was kind of high-schoolish.  \n",
    "        Didn't care for the cliff hanging ending.\"\"\",\n",
    "        \"\"\"I don't know if you are familiar with FANFIC on the internet but that what this book reminded me of.  \n",
    "        I love the series and thought I would like the books...not so much.\"\"\",\n",
    "        \"\"\"As I love western era romances, this one was wonderful.  An easy read and ended the way we always hope....happily!\"\"\"]\n",
    "overall=[4,1,3,2,5]\n",
    "vecs = vectorizer.transform(texts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 1, 3, 2, 5] [ 4.  1.  3.  3.  5.]\n"
     ]
    }
   ],
   "source": [
    "print(overall,logreg.predict(vecs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
