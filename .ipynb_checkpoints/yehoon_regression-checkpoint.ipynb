{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
=======
   "execution_count": 20,
   "metadata": {
    "collapsed": true
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
<<<<<<< HEAD
    "import nltk"
=======
    "import nltk\n",
    "import numpy as np"
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
=======
   "execution_count": 2,
   "metadata": {
    "collapsed": true
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   },
   "outputs": [],
   "source": [
    "with open(\"reviews_Books_5.json\",\"r\") as data_file:\n",
    "    raw_data=data_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
=======
   "execution_count": 3,
   "metadata": {},
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"AAXUNK0W2DZG5\", \"asin\": \"0060520841\", \"reviewerName\": \"Amazon Customer \\\"leneker\\\"\", \"helpful\": [5, 10], \"reviewText\": \"1996 Bernard Goldberg wrote an editorial for the Wall Street Journal that said there was an obvious bias on the part of network new shows  for the liberal point of view.  he then illustrated this with an example that he dissected in-depth.  The reaction to this observation was the ruination of her career, and the beginning of his status as a pariah among most newsmen.  This book is used to add more ammo to the controversy.That the journalists who so eagerly pry into other peoples lives and business should be reluctant to be examined is hardly surprising.  Almost no one really wants to have his life or business dissected by Mike Wallace not even Dan Rather.  Some facts in this book are really potent such as the survey results which show how the average journalist and the average American are often vastly at odds.  Other chapters highlight different stories that TV news has covered and the analysis that Goldberg has made to point out the liberal bias.  His main theme is that while there is no conspiracy of the left, the fact is that most reporters are liberal but fewer still will admit it.There is some sound reasoning behind this book.  Sadly in execution, it doesn't come off as well as it could.  Goldberg has one argument in all the years he worked closely with Dan Rather (according to him) and yet it seems like all they did was fight.  Why ?  because Goldberg replays that one argument about 5 or 6 times in the book.  Much of the material that is thought provoking the first time around is pretty stale after the third or fourth reading. He kindly reprints the editorial that started the whole furor, too bad this was at the end of the book because the entire first chapter is just a rehash of that argument.  Too often Goldberg is reduced sounding like the bitter vindictive perso 93184\n"
     ]
    }
   ],
   "source": [
    "json_list = []\n",
    "for i in range(len(raw_data)):\n",
    "    try:\n",
    "        json_data = json.loads(raw_data[i])\n",
    "        json_list.append(json_data)\n",
    "    except:\n",
    "        print(raw_data[i],i)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
=======
   "execution_count": 4,
   "metadata": {
    "collapsed": true
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   },
   "outputs": [],
   "source": [
    "review_data = []\n",
    "\n",
    "for i in range(len(json_list)):\n",
    "    review_dict={}\n",
    "    review_dict[\"reviewText\"] = json_list[i][\"reviewText\"]\n",
    "    review_dict[\"overall\"] = json_list[i][\"overall\"]\n",
    "    review_dict[\"asin\"] = json_list[i][\"asin\"]\n",
    "    review_data.append(review_dict)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
=======
   "execution_count": 5,
   "metadata": {
    "collapsed": true
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random_data = random.sample(review_data,len(review_data))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
=======
   "execution_count": 6,
   "metadata": {},
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93184"
      ]
     },
<<<<<<< HEAD
     "execution_count": 53,
=======
     "execution_count": 6,
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_data)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
=======
   "execution_count": 7,
   "metadata": {
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93184"
      ]
     },
<<<<<<< HEAD
     "execution_count": 54,
=======
     "execution_count": 7,
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(random_data)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
=======
   "execution_count": 8,
   "metadata": {},
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "{'asin': '006009026X',\n",
       " 'overall': 5.0,\n",
       " 'reviewText': 'This book is fun. You feel like you know the women after you read their stories. Their strength, independence and ability to run a home while their husbands were starting a democracy are admirable.'}"
      ]
     },
     "execution_count": 55,
=======
       "{'asin': '0060513136',\n",
       " 'overall': 5.0,\n",
       " 'reviewText': 'Great for leaning Spanish. Get both languages and make your kid bilingual. This is a classic early reader. Great pictures too.'}"
      ]
     },
     "execution_count": 8,
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_data[0]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
=======
   "execution_count": 9,
   "metadata": {},
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
=======
   "execution_count": 10,
   "metadata": {},
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "This book is fun. You feel like you know the women after you read their stories. Their strength, independence and ability to run a home while their husbands were starting a democracy are admirable.\n",
      "This book is fun. You feel like you know the women after you read their stories. Their strength, independence and ability to run a home while their husbands were starting a democracy are admirable.\n"
=======
      "Great for leaning Spanish. Get both languages and make your kid bilingual. This is a classic early reader. Great pictures too.\n",
      "Great for leaning Spanish. Get both languages and make your kid bilingual. This is a classic early reader. Great pictures too.\n"
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
<<<<<<< HEAD
      "The code that caused this warning is on line 193 of the file c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
=======
      "The code that caused this warning is on line 170 of the file c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Import BeautifulSoup into your workspace\n",
    "from bs4 import BeautifulSoup             \n",
    "\n",
    "# Initialize the BeautifulSoup object on a single movie review     \n",
    "example1 = BeautifulSoup(random_data[0][\"reviewText\"])  \n",
    "\n",
    "# Print the raw review and then the output of get_text(), for \n",
    "# comparison\n",
    "print(random_data[0][\"reviewText\"])\n",
    "print(example1.get_text())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
=======
   "execution_count": 11,
   "metadata": {},
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "This book is fun  You feel like you know the women after you read their stories  Their strength  independence and ability to run a home while their husbands were starting a democracy are admirable \n"
=======
      "Great for leaning Spanish  Get both languages and make your kid bilingual  This is a classic early reader  Great pictures too \n"
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Use regular expressions to do a find-and-replace\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",           # The pattern to search for\n",
    "                      \" \",                   # The pattern to replace it with\n",
    "                      example1.get_text() )  # The text to search\n",
    "print(letters_only)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 159,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
=======
   "execution_count": 37,
   "metadata": {
    "collapsed": true
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   },
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    \n",
    "   \n",
<<<<<<< HEAD
    "    cleaned_review=[]\n",
    "    for i in range(len(raw_review)):\n",
    "        cleaned_text_list=[]\n",
=======
    "    cleaned_text_list=[]\n",
    "    for i in range(len(raw_review)):\n",
    "        \n",
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
    "        review_text = BeautifulSoup(raw_review[i][\"reviewText\"]).get_text()\n",
    "        letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n",
    "        words = letters_only.lower().split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        meaningful_words = [w for w in words if not w in stops]\n",
    "        cleaned_text = \" \".join(meaningful_words)\n",
    "        cleaned_text_list.append(cleaned_text)\n",
    "#         print(cleaned_text_list)\n",
    "    \n",
<<<<<<< HEAD
    "        cleaned_review.append(cleaned_text_list)\n",
    "    print(cleaned_review)  \n",
    "    return cleaned_review\n",
=======
    "#     print(cleaned_review)  \n",
    "    return cleaned_text_list\n",
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
    "                                 \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "                      \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "#     meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
=======
   "execution_count": 46,
   "metadata": {
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
    "scrolled": true
   },
   "outputs": [
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['book fun feel like know women read stories strength independence ability run home husbands starting democracy admirable'], ['read lot bad reviews book pretty reluctant read glad structure different first two books alternates narratives works well way agree ending different expected closes story nicely invested time read books disappointed one great end exciting trilogy'], ['loved book especially story moved present day loved characters wait se whole story would fit together also made look kashmir shawls greater appreciation culture workmanship involved like book takes back time pulls forward present day hen love book really liked pace book ended holiday read books took one captivated feel india like european woman time fascinating'], ['introduction islam frederick denny first edition second edition paperback isbn pgs although medium size paperback book actually worthy called college level textbook chapter early civilizations egypt mesopotamia jews pages christianity pages pre islamic arabia beliefs pgs muhammad early muslim community pages arab conquest pages basic beliefs worship practices islam pages nature function quran format recitation nature interpretation inimitability pgs prophets sunna preserved hadith pgs muslim creeds theologies place reason mutazilited three muslim creeds kalam challenge philosophy pgs law state classical islamic formulations shari fiqh schools law political institutions pgs sufi way mysticism tariqa al junayd sober sufism antinomian intoxicated al hallaj al ghazali pgs master disciples sufi orders shaykhs faqirs qadiri jalal al din al rumi mawlawis silsila dhikr sama ibn arabi pgs islamic life cyle family rites ceremonies customs infancy childhood marriage divorce inheritance property interest food clothing death rituals pgs ideals realities islamic community life mosque marketplace public behavior recreation veneration saints pgs islam modern world wahhabis islam nationalism pgs three forms islamic revival fundamentalism feminism umma north america pgs besides presenting islamic views middle east also covers far east also one informative books era'], ['reading reviews thought would great read wrong gladys ivy two worst characters ever read nothing liked book kept waiting character development never came stories rambled dysfunctionality ran rampant lives characters read whole thing even though stopped chapters wanted see rave reviews talking read least book week wasted week']]\n"
     ]
    },
    {
=======
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html5lib\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
<<<<<<< HEAD
      "The code that caused this warning is on line 193 of the file c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
=======
      "The code that caused this warning is on line 170 of the file c:\\users\\jangy\\miniconda3\\envs\\bi_project\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html5lib\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "cleaned_review=review_to_words(random_data[:5])"
=======
    "random_review_data=review_to_words(random_data)"
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
=======
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(random_review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', sublinear_tf=True, max_df = 0.5, lowercase=True, stop_words = 'english')\n",
    "D = vectorizer.fit_transform(random_review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93184, 112359)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = []\n",
    "int_y_data = []\n",
    "for i in range(len(random_data)):\n",
    "    y_data.append(random_data[i][\"overall\"])\n",
    "y_data=np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(D, y_data, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logistioc Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True, False,  True, ...,  True,  True,  True], dtype=bool)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression()\n",
    "\n",
    "logreg.fit(x_train, y_train)\n",
    "logreg.predict(x_test) == y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62703224767934751"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(logreg.predict(x_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>그냥</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'datetime' has no attribute 'now'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-3daf8967e157>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# train the classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'datetime' has no attribute 'now'"
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "print(clean_review)"
=======
    "from sklearn.svm import LinearSVC\n",
    "import datetime\n",
    " \n",
    "# initialise the SVM classifier\n",
    "classifier = LinearSVC()\n",
    " \n",
    "# train the classifier\n",
    "t1 = datetime.now()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(datetime.now() - t1)"
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
<<<<<<< HEAD
    "collapsed": true,
    "deletable": true,
    "editable": true
=======
    "collapsed": true
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
<<<<<<< HEAD
=======
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
>>>>>>> 8ffe6566f0afa0954d7052203aaf59c96f2a42d8
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
